---
title: "Probability Fundamentals"
subtitle: "Lecture 04"
author: "Vivek Srikrishnan"
course: "BEE 4850"
institution: "Cornell University"
date: "February 03, 2024"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
        email-obfuscation: javascript
        chalkboard:
            theme: whiteboard
            buttons: true
        mermaid: 
            theme: dark
engine: julia
filters:
  - code-fullscreen
---

```{julia}
#| output: false

import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
#| output: false

using Random
using DataFrames
using DataFramesMeta
using CSV
using Dates
using Distributions
using ColorSchemes
using Plots
using StatsPlots
using StatsBase
using GLM
using Optim
using LaTeXStrings
using Measures

Random.seed!(1)

plot_font = "Computer Modern"
default(
    fontfamily=plot_font,
    linewidth=3, 
    framestyle=:box, 
    label=nothing, 
    grid=false,
    guidefontsize=18,
    legendfontsize=16,
    tickfontsize=16,
    titlefontsize=20,
    bottom_margin=10mm,
    left_margin=5mm
)
```

# Review

## Null Hypothesis Significance Testing

- Binary "significant"/"non-significant" decision framework;
- Accept or reject null hypothesis $H_0$ based on p-value of test statistic;
- "Typical" statistical models for $H_0$ often chosen out of computational convenience
- **There be dragons**: Multiple comparisons, lack of statistical power, reading rejection of $H_0$ as acceptance of alternative $H$

## Generative Modeling

- **Generative model**: Fully specify data generating process with joint probability distribution over parameters
- Simulation lets us construct predictive distributions for further analysis.

# Probability "Review"

## What is Uncertainty?

::: {.fragment .fade-in}
::: {.quote}
> ...A  departure  from  the  (unachievable)  ideal  of  complete  determinism...

::: {.cite}
--- @Walker2003-zi
:::
:::
:::

## Types of Uncertainty

::: {.fragment .fade-in}
:::: {.columns}
::: {.column width=60%}

| Uncertainty Type | Source | Example(s) |
|:----------------:|:-------|:-----------|
| ***Aleatory uncertainty*** | Randomness | Dice rolls, Instrument imprecision |
| ***Epistemic uncertainty*** | Lack of knowledge | Climate sensitivity, Premier League champion|

:::
::: {.column width=40%}

![Which Uncertainty Type Meme](memes/uncertainty_types.png){width=75%}

:::
::::
:::

::: {.notes}
Note that the distinction between aleatory and epistemic uncertainty is somewhat arbitrary (aside from maybe some quantum effects). For example, we often think of coin tosses as aleatory, but if we had perfect information about the toss, we might be able to predict the outcome with less uncertainty. There's a famous paper by Persi Diaconis where he collaborated with engineers to build a device which could arbitrary bias a "fair" coin toss.

But in practice, this doesn't really matter: the key thing is whether for a given model we're treating the uncertainty as entirely random (e.g. white noise) versus being interested in the impacts of that uncertainty on the outcome of interest. And there's a representation theorem by the Bayesian actuary Bruno de Finetti which shows that, under a condition called *exchangeability*, we can think of any random sequence as arising from an independent and identically distributed process, so the practical difference can collapse further.
:::

## Probability

Probability is a language for expressing uncertainty.

The **axioms of probability** are straightforward:

1. $\mathcal{P}(E) \geq 0$;
2. $\mathcal{P}(\Omega) = 1$;
3. $\mathcal{P}(\cup_{i=1}^\infty E_i) = \sum_{i=1}^\infty \mathcal{P}(E_i)$ for disjoint $E_i$.

::: {.notes}
The third is a generalization of the definition of independent events to sets of outcomes.
:::

## Frequentist vs Bayesian Probability

:::: {.columns}
::: {.column width=50%}
**Frequentist**:

- Probability as frequency over repeated observations.
- Data are random, but parameters are not.
- How consistent are estimates for different data?
:::

::: {.column width=50%}
::: {.fragment .fade-in}
**Bayesian**:

- Probability as degree of belief/betting odds.
- Data and parameters are random variables;
- Emphasis on **conditional probability**.

:::
:::
::::


## But What, Like, **Is** Probability?

::: {.fragment .fade-in}
:::: {.columns}
::: {.column width=50%}
Frequentist vs. Bayesian: different interpretations with some different methods and formalisms.

We will freely borrow from each school depending on the purpose and goal of an analysis.
:::

::: {.column width=50%}
![Definitions of Probability Meme](memes/probability_definitions.png)

:::
::::
:::

## Probability Distributions

Distributions are mathematical representations of probabilities over a range of possible outcomes.

$$x \to \mathbb{P}_{\color{green}\nu}[x] = p_{\color{green}\nu}\left(x | {\color{purple}\theta}\right)$$

- ${\color{green}\nu}$: probability distribution (often implicit);
- ${\color{purple}\theta}$: distribution parameters

## Sampling Notation

To write $x$ is sampled from $p(x|\theta)$:
$$x \sim f(\theta)$$

For example, for a normal distribution:
$$x \overset{\text{i.i.d.}}{\sim} \mathcal{N}(\mu, \sigma)$$

::: {.notes}
"i.i.d." means "identically and independently distributed.""
:::

## Probability Density Function

A continuous distribution $\mathcal{D}$ has a probability density function (PDF) $f_\mathcal{D}(x) = p(x | \theta)$.

The probability of $x$ occurring in an interval $(a, b)$ is
$$\mathbb{P}[a \leq x \leq b] = \int_a^b f_\mathcal{D}(x)dx.$$

**Important**: $\mathbb{P}(x = x^*)$, is zero!

## Probability Mass Functions

Discrete distributions have *probability mass functions* (PMFs) which are defined at point values, e.g. $p(x = x^*) \neq 0$.

::: {.notes}
Unlike continuous distributions, we can talk about the probability of individual values for discrete distributions, which a PMF provides versus a PDF. But in general these are the same things.
:::


## Cumulative Density Functions

:::: {.columns}
::: {.column width=50%}
If $\mathcal{D}$ is a distribution with PDF $f_\mathcal{D}(x)$, the **cumulative density function** (CDF) of $\mathcal{D}$ $F_\mathcal{D}(x)$:

$$F_\mathcal{D}(x) = \int_{-\infty}^x f_\mathcal{D}(u)du.$$

:::
::: {.column width=50%}
```{julia}
#| label: fig-cdf-pdf
#| fig-cap: Relationship of CDF and PDF
#| layout-nrow: 2
dist = TDist(4)
x = -5:0.01:5
q = 0.25
p1 = plot(x, x -> cdf(dist, x), ylabel="Cumulative Density", xlabel=L"$x$", linewidth=3, label=false)
plot!([-5, quantile(dist, q)], [q, q], color=:gray, linestyle=:dash, linewidth=2, label=false)
plot!([quantile(dist, q), quantile(dist, q)], [0, q], color=:gray, linestyle=:dash, linewidth=2, label=false, size=(500, 300))

p2 = plot(x, x -> pdf(dist, x), linewidth=3, ylabel="Density", xlabel=L"$x$", label=false)
xpdf = -5:0.01:quantile(dist, q)
plot!(xpdf, zeros(length(xpdf)), fillrange=pdf.(dist, xpdf), fillalpha=0.5, color=:gray, label=false, size=(500, 300))

display(p1)
display(p2)
```
:::
::::

## Relationship Between PDFs and CDFs

Since $$F_\mathcal{D}(x) = \int_{-\infty}^x f_\mathcal{D}(u)du,$$

if $f_\mathcal{D}$ is continuous at $x$, the Fundamental Theorem of Calculus gives:
$$f_\mathcal{D}(x) = \frac{d}{dx}F_\mathcal{D}(x).$$

::: {.notes}
The value of the CDF is the amount of probability "below" the value. So e.g. for a one-sided statistical test, the p-value is the complement of the CDF at the value of the test statistic.
:::

## Quantiles

:::: {.columns}
::: {.column width=50%}
The quantile function is the **inverse of the CDF**:

$$q(\alpha) = F^{-1}_\mathcal{D}(\alpha)$$

So $$x_0 = q(\alpha) \iff \mathbb{P}_\mathcal{D}(X < x_0) = \alpha.$$

:::
::: {.column width=50%}
```{julia}
#| label: fig-cdf-pdf-2
#| fig-cap: Relationship of CDF and PDF
#| layout-nrow: 2
dist = TDist(4)
x = -5:0.01:5
q = 0.25
p1 = plot(x, x -> cdf(dist, x), ylabel="Cumulative Density", xlabel=L"$x$", linewidth=3, label=false)
plot!([-5, quantile(dist, q)], [q, q], color=:gray, linestyle=:dash, linewidth=2, label=false)
plot!([quantile(dist, q), quantile(dist, q)], [0, q], color=:gray, linestyle=:dash, linewidth=2, label=false, size=(500, 300))

p2 = plot(x, x -> pdf(dist, x), linewidth=3, ylabel="Density", xlabel=L"$x$", label=false)
xpdf = -5:0.01:quantile(dist, q)
plot!(xpdf, zeros(length(xpdf)), fillrange=pdf.(dist, xpdf), fillalpha=0.5, color=:gray, label=false, size=(500, 300))

display(p1)
display(p2)
```
:::
::::

# Selecting a Distribution

## Distributions Are Assumptions

**Specifying a distribution is making an assumption about observations and any applicable constraints.**

Examples: If your observations are...

- Continuous and fat-tailed? **Cauchy distribution**
- Continuous and bounded? **Beta distribution**
- Sums of positive random variables? **Gamma or Normal distribution**.

## Why Use a Normal Distribution?

:::: {.columns}
::: {.column width=60%}
Two main reasons to use linear models/normal distributions:

1. **Inferential**: "Least informative" distribution assuming knowledge of just mean and variance;
2. **Generative**: Central Limit Theorem (summed fluctuations are asymptotically normal)

:::
::: {.column width=40%}
![Weight stack Gaussian distribution](https://i.redd.it/zl5mo1n45wyb1.jpg)

::: {.caption}
Source: r/GymMemes
:::
:::
::::

::: {.notes}
One key thing: normal distributions are the "least informative" distribution given constraints on mean and variance. So all else being equal, this is a useful machine if all we're interested in are those two moments.
:::

## Central Limit Theorem: Sampling Distributions

**The sum or mean of a random sample is itself a random variable**:

$$\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i \sim \mathcal{D}_n$$

::: {.fragment .fade-in}
$\mathcal{D}_n$: The ***sampling distribution*** of the mean (or sum, or other estimate of interest).
:::

## Central Limit Theorem 

If 

- $\mathbb{E}[X_i] = \mu$ 
- and $\text{Var}(X_i) = \sigma^2 < \infty$, 

$$\begin{align*}
&\bbox[yellow, 10px, border:5px solid red]
{\lim_{n \to \infty} \sqrt{n}(\bar{X}_n - \mu ) = \mathcal{N}(0, \sigma^2)} \\
\Rightarrow &\bbox[yellow, 10px, border:5px solid red] {\bar{X}_n \overset{\text{approx}}{\sim} \mathcal{N}(\mu, \sigma^2/n)}
\end{align*}$$

## Central Limit Theorem (More Intuitive)

For **a large enough set of samples**, the sampling distribution of a sum or mean of random variables is approximately a normal distribution, even if the random variables themselves are not.


## "What Distribution Should I Use?"

**There is no right answer to this, no matter what a statistical test tells you.**

- What assumptions are justifiable from theory?
- What information do you have? 

## "What Distribution Should I Use?"

For example, suppose our data are counts of events:

- If you know something about **rates**, you can use a Poisson distribution
- If you know something about **probabilities**, you can use a Binomial distribution. 

## Q-Q Plots

::: {.columns}
::: {.column width=50%}
One exploratory method to see if your data is reasonably described by a theoretical distribution is a **Q-Q plot**.
:::
::: {.column width=50%}
```{julia}
#| label: fig-norm-qq
#| code-fold: true
#| code-overflow: wrap
#| echo: true

samps = rand(Normal(0, 3), 20)
qqplot(Normal, samps, tickfontsize=16, guidefontsize=18, linewidth=3, markersize=6)
xlabel!("Theoretical Quantiles")
ylabel!("Empirical Quantiles")
plot!(size=(500, 450))
```
:::
::::

## Fat-Tailed Data and Q-Q Plots

```{julia}
#| label: fig-cauchy-qq
#| echo: false
#| layout-nrow: 2
#| fig-cap: "Q-Q Plot for Cauchy Data and Normal Distribution"
#| fig-subcap: 
#|  - "Normal vs Cauchy Distribution"
#|  - "Q-Q Plot"

## generate fat-tailed residuals
cauchy_samps = rand(Cauchy(0, 0.05), 50)

# make plots
# scatterplot of observations
p1 = plot(fit(Normal, cauchy_samps), linewidth=3, color=:green, label="Normal Distribution", yaxis=false, legend=:outerright)
plot!(p1, fit(Cauchy, cauchy_samps), linewidth=3, color=:orange, linestyle=:dash, label="Cauchy Distribution")
scatter!(p1, cauchy_samps, zeros(length(cauchy_samps)), markersize=3, color=:black, label="Data")
xlims!(p1, (-2, 2))
xlabel!("Value")
plot!(p1, size=(1000, 250))

# densities of residual distributions
p2 = qqplot(Normal, cauchy_samps, tickfontsize=16, guidefontsize=18, linewidth=3, markersize=6, title="Normal Q-Q Plot")
xlabel!(p2, "Theoretical Values")
ylabel!(p2, "Empirical Values")
p3 = qqplot(Cauchy, cauchy_samps, tickfontsize=16, guidefontsize=18, linewidth=3, markersize=6, title="Cauchy Q-Q Plot")
xlabel!(p3, "Theoretical Values")
ylabel!(p3, "Empirical Values")
p = plot(p2, p3, layout=(1, 2), size=(900, 350))

display(p1)
display(p)
```


## Likelihood

How do we "fit" distributions to a dataset?

**Likelihood** of data to have come from distribution $f(\mathbf{x} | \theta)$:

$$\mathcal{L}(\theta | \mathbf{x}) = \underbrace{f(\mathbf{x} | \theta)}_{\text{PDF}}$$

::: {.notes}
The likelihood gives us a measure of how probable a dataset is from a given distribution. It's the PDF of the distribution at the data.

But the perspective is flipped: instead of fixing a distribution and calculating the probability of some data, we fix the data and look at how the probability of observing that data changes as the distribution changes. 
:::


## Normal Distribution PDF

$$f_\mathcal{D}(x) = p(x | \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{1}{2}\left(\frac{x - \mu}{\sigma}^2\right)\right)$$

::: {.center}
```{julia}
#| label: fig-normal
#| fig-align: center

plot(Normal(0, sqrt(3)), linewidth=3, color=:blue, label=L"$\mu=0$, $\sigma=\sqrt{3}$", guidefontsize=20, legendfontsize=20, tickfontsize=14)
plot!(Normal(2, 1), linewidth=3, color=:orange, label=L"$\mu=2$, $\sigma=1$")
plot!(Normal(0, 1), linewidth=3, color=:red, label=L"$\mu=0$, $\sigma=1$")
plot!(size=(1200, 400), left_margin=10mm, bottom_margin=10mm)
vline!([0.5], color=:black, linestyle=:dash)
xlabel!(L"$x$")
ylabel!("Likelihood")
xlims!((-5, 5))
```
:::

## Likelihood of Multiple Samples

For multiple (independent) samples $\mathbf{x} = \{x_1, \ldots, x_n\}$:

$$\mathcal{L}(\theta | \mathbf{x}) = \prod_{i=1}^n \mathcal{L}(\theta | x_i).$$

## Likelihood Example

:::: {.columns}
::: {.column width=50%}
```{julia}

dist = Normal(-0.5, 2)
x = rand(dist, 10)
plot(Normal(0, 1), linewidth=3, ylabel="Density", xlabel=L"$x$", legend=false, color=:blue, size=(600, 400))
vline!(x, color=:red)
xlims!((-9, 6))
```
:::
::: {.column width=50%}
| Distribution | Likelihood |
|:------------:|:-----------|
| $N(0, 1)$ | `{julia} round(prod(pdf.(Normal(0, 1), x)); sigdigits=2)` |
:::
::::

## Likelihood Example

:::: {.columns}
::: {.column width=50%}
```{julia}

plot(Normal(0, 1), linewidth=3, ylabel="Density", xlabel=L"$x$", alpha=0.2, legend=false, color=:blue, size=(600, 400))
plot!(Normal(-1, 2), linewidth=3, color=:blue)
vline!(x, color=:red)
xlims!((-9, 6))
```
:::
::: {.column width=50%}
| Distribution | Likelihood |
|:------------:|:-----------|
| $N(0, 1)$ | `{julia} round(prod(pdf.(Normal(0, 1), x)); sigdigits=2)` |
| $N(-1, 2)$ | `{julia} round(prod(pdf.(Normal(-1, 2), x)); sigdigits=2)` |
:::
::::

## Likelihood Example

:::: {.columns}
::: {.column width=50%}
```{julia}

plot(Normal(0, 1), linewidth=3, ylabel="Density", xlabel=L"$x$", alpha=0.2, legend=false, color=:blue, size=(600, 400))
plot!(Normal(-1, 2), linewidth=3, color=:blue, alpha=0.2)
plot!(Normal(-1, 1), linewidth=3, color=:blue)
vline!(x, color=:red)
xlims!((-9, 6))
```
:::
::: {.column width=50%}
| Distribution | Likelihood |
|:------------:|:-----------|
| $N(0, 1)$ | `{julia} round(prod(pdf.(Normal(0, 1), x)); sigdigits=2)` |
| $N(-1, 2)$ | `{julia} round(prod(pdf.(Normal(-1, 2), x)); sigdigits=2)` |
| $N(-1, 1)$ | `{julia} round(prod(pdf.(Normal(-1, 1), x)); sigdigits=2)` |
:::
::::

## Maximizing Likelihood

To find the parameters $\hat{\theta}$ which best fit the data:

$\hat{\theta} = \max_\theta \mathcal{L}(\theta | \mathbf{x})$

## Generally Maximizing Likelihood

:::: {.columns}
::: {.column width=50%}
Can use optimization algorithms to maximize $\theta \to \mathcal{L}(\theta | x).$

**Dragons**: Probability calculations tend to under- and overflow due to floating point precision.
:::
::: {.column width=50%}
![Floating Point Logarithms meme](memes/floating_point_logs.png){width=85%}
:::
::::

# Describing Uncertainty


## Confidence Intervals

:::: {.columns}
::: {.column width=50%}
Frequentist estimates have **confidence intervals**, which will contain the "true" parameter value for $\alpha$% of data samples.

No guarantee that an individual CI contains the true value (with any "probability")!
:::

::: {.column width=50%}

![Horseshoe Illustration](https://www.wikihow.com/images/thumb/2/20/Throw-a-Horseshoe-Step-4-Version-4.jpg/aid448076-v4-728px-Throw-a-Horseshoe-Step-4-Version-4.jpg){width=90%}

::: {.caption}
Source: <https://www.wikihow.com/Throw-a-Horseshoe>
:::

:::
::::

::: {.notes}
Confidence intervals only capture uncertainty in **parameter inferences** due to data uncertainty, though this language sometimes gets misused to also refer to data/estimand uncertainty. 

:::

## Example: 95% CIs for N(0.4, 2)

```{julia}
#| label: fig-cis
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| layout-ncol: 2
#| fig-cap: "Display of 95% confidence intervals"
#| fig-subcap: 
#|  - "Sample Size 100"
#|  - "Sample Size 1,000"

# set up distribution
mean_true = 0.4
n_cis = 100 # number of CIs to compute
dist = Normal(mean_true, 2)

# use sample size of 100
samples = rand(dist, (100, n_cis))
# mapslices broadcasts over a matrix dimension, could also use a loop
sample_means = mapslices(mean, samples; dims=1)
sample_sd = mapslices(std, samples; dims=1) 
mc_sd = 1.96 * sample_sd / sqrt(100)
mc_ci = zeros(n_cis, 2) # preallocate
for i = 1:n_cis
    mc_ci[i, 1] = sample_means[i] - mc_sd[i]
    mc_ci[i, 2] = sample_means[i] + mc_sd[i]
end
# find which CIs contain the true value
ci_true = (mc_ci[:, 1] .< mean_true) .&& (mc_ci[:, 2] .> mean_true)
# compute percentage of CIs which contain the true value
ci_frac1 = 100 * sum(ci_true) ./ n_cis

# plot CIs
p1 = plot([mc_ci[1, :]], [1, 1], linewidth=3, color=:deepskyblue, label="95% Confidence Interval", title="Sample Size 100", yticks=:false, legend=:false)
for i = 2:n_cis
    if ci_true[i]
        plot!(p1, [mc_ci[i, :]], [i, i], linewidth=2, color=:deepskyblue, label=:false)
    else
        plot!(p1, [mc_ci[i, :]], [i, i], linewidth=2, color=:red, label=:false)
    end
end
vline!(p1, [mean_true], color=:black, linewidth=2, linestyle=:dash, label="True Value") # plot true value as a vertical line
xaxis!(p1, "Estimate")
plot!(p1, size=(500, 350)) # resize to fit slide

# use sample size of 1000
samples = rand(dist, (1000, n_cis))
# mapslices broadcasts over a matrix dimension, could also use a loop
sample_means = mapslices(mean, samples; dims=1)
sample_sd = mapslices(std, samples; dims=1) 
mc_sd = 1.96 * sample_sd / sqrt(1000)
mc_ci = zeros(n_cis, 2) # preallocate
for i = 1:n_cis
    mc_ci[i, 1] = sample_means[i] - mc_sd[i]
    mc_ci[i, 2] = sample_means[i] + mc_sd[i]
end
# find which CIs contain the true value
ci_true = (mc_ci[:, 1] .< mean_true) .&& (mc_ci[:, 2] .> mean_true)
# compute percentage of CIs which contain the true value
ci_frac2 = 100 * sum(ci_true) ./ n_cis

# plot CIs
p2 = plot([mc_ci[1, :]], [1, 1], linewidth=3, color=:deepskyblue, label="95% Confidence Interval", title="Sample Size 1,000", yticks=:false, legend=:false)
for i = 2:n_cis
    if ci_true[i]
        plot!(p2, [mc_ci[i, :]], [i, i], linewidth=2, color=:deepskyblue, label=:false)
    else
        plot!(p2, [mc_ci[i, :]], [i, i], linewidth=2, color=:red, label=:false)
    end
end
vline!(p2, [mean_true], color=:black, linewidth=2, linestyle=:dash, label="True Value") # plot true value as a vertical line
xaxis!(p2, "Estimate")
plot!(p2, size=(500, 350)) # resize to fit slide

display(p1)
display(p2)
```

`{julia} Int64(round(ci_frac1))`% of the CIs contain the true value (left) vs. `{julia} Int64(round(ci_frac2))`% (right)

## Predictive Intervals

:::: {.columns}
::: {.column width=50%}
**Predictive intervals** capture uncertainty in an estimand.

**With what probability would I see a particular outcome in the future?**

Often need to construct these using **simulation**.
:::
::: {.column width=50%}
```{julia}
#| label: fig-credible-interval
#| fig-cap: Two different 95% credible intervals.

plot(Gamma(7.5), linewidth=3, xlabel="Data/Parameter", label=:false, legend=:outerbottom)
q1 = quantile(Gamma(7.5), [0.05, 0.95])
q2 = quantile(Gamma(7.5), [0.01, 0.91])
q3 = quantile(Gamma(7.5), [0.09, 0.99])
gamma_pdf(x) = pdf(Gamma(7.5), x)
plot!(q1[1]:0.01:q1[2], gamma_pdf(q1[1]:0.01:q1[2]), fillrange=zero(q1[1]:0.01:q1[2]), alpha=0.2, label="90% Interval 1")
plot!(q2[1]:0.01:q2[2], gamma_pdf(q2[1]:0.01:q2[2]), fillrange=zero(q2[1]:0.01:q2[2]), alpha=0.2, label="90% Interval 2")
plot!(q3[1]:0.01:q3[2], gamma_pdf(q3[1]:0.01:q3[2]), fillrange=zero(q3[1]:0.01:q3[2]), alpha=0.2, label="90% Interval 3")
plot!(size=(600, 650))
```
:::
::::

::: {.notes}
Due to this non-uniqueness, the typical convention is to use the "equal tailed" interval based on quantiles.
:::


# Upcoming Schedule

## Next Classes

**Wednesday**: Bayesian Statistics

**Next Week**: Temporal and Spatial Models and Errors

## Assessments

**Homework 1** due Friday (2/7).

# References

## References (Scroll for Full List)
