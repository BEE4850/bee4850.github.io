---
title: "Probability Models for Data"
subtitle: "Lecture 04"
author: "Vivek Srikrishnan"
course: "BEE 4850"
institution: "Cornell University"
date: "February 03, 2024"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: mathjax
        include-in-header: mathjax-config.html
        date-format: long
        email-obfuscation: javascript
        chalkboard:
            theme: whiteboard
            buttons: true
        mermaid: 
            theme: dark
engine: julia
filters:
  - code-fullscreen
---

```{julia}
#| output: false

import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
#| output: false

using Random
using DataFrames
using DataFramesMeta
using CSV
using Dates
using Distributions
using ColorSchemes
using Plots
using StatsPlots
using StatsBase
using GLM
using Optim
using LaTeXStrings
using Measures

Random.seed!(1)

plot_font = "Computer Modern"
default(
    fontfamily=plot_font,
    linewidth=3, 
    framestyle=:box, 
    label=nothing, 
    grid=false,
    guidefontsize=18,
    legendfontsize=16,
    tickfontsize=16,
    titlefontsize=20,
    bottom_margin=10mm,
    left_margin=5mm
)
```

# Review

## Probability Fundamentals



## Generative Modeling

- **Generative model**: Fully specify data generating process with joint probability distribution over parameters
- Simulation lets us construct predictive distributions for further analysis.

# Probability "Review"

## What is Uncertainty?

::: {.fragment .fade-in}
::: {.quote}
> ...A  departure  from  the  (unachievable)  ideal  of  complete  determinism...

::: {.cite}
--- @Walker2003-zi
:::
:::
:::

## Types of Uncertainty

::: {.fragment .fade-in}
:::: {.columns}
::: {.column width=60%}

| Uncertainty Type | Source | Example(s) |
|:----------------:|:-------|:-----------|
| ***Aleatory uncertainty*** | Randomness | Dice rolls, Instrument imprecision |
| ***Epistemic uncertainty*** | Lack of knowledge | Climate sensitivity, Premier League champion|

:::
::: {.column width=40%}

![Which Uncertainty Type Meme](memes/uncertainty_types.png){width=75%}

:::
::::
:::

::: {.notes}
Note that the distinction between aleatory and epistemic uncertainty is somewhat arbitrary (aside from maybe some quantum effects). For example, we often think of coin tosses as aleatory, but if we had perfect information about the toss, we might be able to predict the outcome with less uncertainty. There's a famous paper by Persi Diaconis where he collaborated with engineers to build a device which could arbitrary bias a "fair" coin toss.

But in practice, this doesn't really matter: the key thing is whether for a given model we're treating the uncertainty as entirely random (e.g. white noise) versus being interested in the impacts of that uncertainty on the outcome of interest. And there's a representation theorem by the Bayesian actuary Bruno de Finetti which shows that, under a condition called *exchangeability*, we can think of any random sequence as arising from an independent and identically distributed process, so the practical difference can collapse further.
:::

## Kolmogorov Axioms

The **axioms of probability** are straightforward:

1. $\mathcal{P}(E) \geq 0$;
2. $\mathcal{P}(\Omega) = 1$;
3. $\mathcal{P}(\cup_{i=1}^\infty E_i) = \sum_{i=1}^\infty \mathcal{P}(E_i)$ for disjoint $E_i$.

::: {.notes}
The third is a generalization of the definition of independent events to sets of outcomes.
:::

## Frequentist vs Bayesian Probability

:::: {.columns}
::: {.column width=50%}
**Frequentist**:

- Probability as frequency over repeated observations.
- Data are random, but parameters are not.
- How consistent are estimates for different data?
:::

::: {.column width=50%}
::: {.fragment .fade-in}
**Bayesian**:

- Probability as degree of belief/betting odds.
- Data and parameters are random variables;
- Emphasis on **conditional probability**.

:::
:::
::::


## But What, Like, **Is** Probability?

::: {.fragment .fade-in}
:::: {.columns}
::: {.column width=50%}
Frequentist vs. Bayesian: different interpretations with some different methods and formalisms.

We will freely borrow from each school depending on the purpose and goal of an analysis.
:::

::: {.column width=50%}
![Definitions of Probability Meme](memes/probability_definitions.png)

:::
::::
:::

## Probability Distributions

$$x \to \mathbb{P}_{\color{green}\nu}[x] = p_{\color{green}\nu}\left(x | {\color{purple}\theta}\right)$$

- ${\color{green}\nu}$: probability distribution (often implicit);
- ${\color{purple}\theta}$: distribution parameters

## Sampling Notation

To write $x$ is sampled from $p(x|\theta)$:
$$x \sim f(\theta)$$

For example, for a normal distribution:
$$x \overset{\sim}{\text{i.i.d.}} \mathcal{N}(\mu, \sigma)$$

::: {.notes}
"i.i.d." means "identically and independently distributed.""
:::

## Probability Density Function

A continuous distribution $\mathcal{D}$ has a probability density function (PDF) $f_\mathcal{D}(x) = p(x | \theta)$.

The probability of $x$ occurring in an interval $(a, b)$ is
$$\mathbb{P}[a \leq x \leq b] = \int_a^b f_\mathcal{D}(x)dx.$$

::: {.callout-important}
The probability that $x$ has a specific value $x^*$, $\mathbb{P}(x = x^*)$, is zero!
:::

## Probability Mass Functions

Discrete distributions have *probability mass functions* (PMFs) which are defined at point values, e.g. $p(x = x^*) \neq 0$.

::: {.notes}
Unlike continuous distributions, we can talk about the probability of individual values for discrete distributions, which a PMF provides versus a PDF. But in general these are the same things.
:::


## Cumulative Density Functions

If $\mathcal{D}$ is a distribution with PDF $f_\mathcal{D}(x)$, the **cumulative density function** (CDF) of $\mathcal{D}$ $F_\mathcal{D}(x)$:

$$F_\mathcal{D}(x) = \int_{-\infty}^x f_\mathcal{D}(u)du.$$

If $f_\mathcal{D}$ is continuous at $x$:
$$f_\mathcal{D}(x) = \frac{d}{dx}F_\mathcal{D}(x).$$

::: {.notes}
The value of the CDF is the amount of probability "below" the value. So e.g. for a one-sided statistical test, the p-value is the complement of the CDF at the value of the test statistic.
:::

# Linear Model Example

## How Does TDS Affect River Flow?

:::: {.columns}
::: {.column width=50%}
**Question**: Does river flow affect the concentration of total dissolved solids?

**Data**: Cuyahoga River (1969 -- 1973), from @Helsel2020-nq [Chapter 9].

:::

::: {.column width=50%}
```{julia}
tds = let
	fname = "data/tds/cuyaTDS.csv" # CHANGE THIS!
	tds = DataFrame(CSV.File(fname))
	tds[!, [:date, :discharge_cms, :tds_mgL]]
end

p = scatter(
	tds.discharge_cms,
	tds.tds_mgL,
	xlabel=L"Discharge (m$^3$/s)",
	ylabel="Total dissolved solids (mg/L)",
    markersize=5,
	label="Observations"
)
plot!(p, size=(600, 600))
```
:::
::::

## How Does TDS Affect River Flow?

:::: {.columns}
::: {.column width=50%}
**Question**: Does river flow affect the concentration of total dissolved solids?


**Model**: 

$$D \rightarrow S \ {\color{purple}\leftarrow U}$$

$$S = f(D, U)$$
:::

::: {.column width=50%}
```{julia}
p
```
:::
::::

## Why Use a Linear Model?

:::: {.columns}
::: {.column width=60%}
Two main reasons to use linear models/normal distributions:

1. **Inferential**: "Least informative" distribution assuming knowledge of just mean and variance;
2. **Generative**: Central Limit Theorem (summed fluctuations are asymptotically normal)

:::
::: {.column width=40%}
![Weight stack Gaussian distribution](https://i.redd.it/zl5mo1n45wyb1.jpg)

::: {.caption}
Source: r/GymMemes
:::
:::
::::

::: {.notes}
One key thing: normal distributions are the "least informative" distribution given constraints on mean and variance. So all else being equal, this is a useful machine if all we're interested in are those two moments.
:::

## Log-Linear Relationships

:::: {.columns}
::: {.column width=50%}
While the original relationship didn't look linear, we can use a log transform on the x-axis.

The model is then:

$$
\begin{align*}
S &= \beta_0 + \beta_1 \log(D) + U\\
U &\sim \mathcal{N}(0, \sigma^2)\\
H &\sim \text{Uniform}(0, 100)
\end{align*}
$$
:::

::: {.column width=50%}
```{julia}
xx = [2, 5, 10, 20, 50, 100]
p1 = plot(p, xaxis=:log, xticks=(xx, string.(xx)))
```
:::
::::

## Likelihood

How do we find $\beta_i$ and $\sigma$?

**Likelihood** of data to have come from distribution $f(\mathbf{x} | \theta)$:

$$\mathcal{L}(\theta | \mathbf{x}) = \underbrace{f(\mathbf{x} | \theta)}_{\text{PDF}}$$

Here the randomness comes from $U$:

$$S \sim \mathcal{N}(\beta_0 + \beta_1 \log(D), \sigma^2)$$

::: {.notes}
The likelihood gives us a measure of how probable a dataset is from a given distribution. It's the PDF of the distribution at the data.

But the perspective is flipped: instead of fixing a distribution and calculating the probability of some data, we fix the data and look at how the probability of observing that data changes as the distribution changes. 
:::


## Normal Distribution PDF

$$f_\mathcal{D}(x) = p(x | \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{1}{2}\left(\frac{x - \mu}{\sigma}^2\right)\right)$$

::: {.center}
```{julia}
#| label: fig-normal
#| fig-align: center

plot(Normal(0, sqrt(3)), linewidth=3, color=:blue, label=L"$\mu=0$, $\sigma=\sqrt{3}$", guidefontsize=20, legendfontsize=20, tickfontsize=14)
plot!(Normal(2, 1), linewidth=3, color=:orange, label=L"$\mu=2$, $\sigma=1$")
plot!(Normal(0, 1), linewidth=3, color=:red, label=L"$\mu=0$, $\sigma=1$")
plot!(size=(1200, 400), left_margin=10mm, bottom_margin=10mm)
xlabel!(L"$x$")
ylabel!("Probability Density")
xlims!((-5, 5))
```
:::

## Back to the Problem...

:::: {.columns}
::: {.column width=50%}
We can fit models by maximizing the likelihood (OLS for this linear model).

```{julia}
#| output: false

m = lm(@formula(tds_mgL ~ log(discharge_cms)), tds)
β = Int.(round.(coef(m), digits=0))
```

$\hat{\beta_0}$: `{julia} β[1]` 

$\hat{\beta_1}$: `{julia} β[2]` 

$\hat{\sigma}^2$: `{julia} Int(round(dispersion(m.model), digits=0))`$^2$

:::

::: {.column width=50%}

```{julia}
Ŝ = sort(predict(m, tds, interval=:prediction), rev=true)
plot!(p1, 
    sort(tds.discharge_cms),
    Ŝ.prediction, 
    ribbon=(Ŝ.prediction - Ŝ.lower, Ŝ.upper - Ŝ.prediction), 
    linewidth=3, 
    fillalpha=0.2, 
    label="Best Fit")
```

:::
::::

## Maximizing Likelihood

:::: {.columns}
::: {.column width=50%}
More generally, can use optimization algorithms to maximize $\theta \to f(\theta | x).$

**Dragons**: Probability calculations tend to under- and overflow due to floating point precision.
:::
::: {.column width=50%}
![Floating Point Logarithms meme](memes/floating_point_logs.png){width=75%}
:::
::::

## Maximizing Likelihood: Julia Example

:::: {.columns}
::: {.column width=70%}
```{julia}
#| echo: true
#| code-fold: false
#| output: false

# function for the log-likelihood
# θ is a vector of parameters: intercept, slope, standard deviation
# y is the observations (TDS)
# x is the predictors (Discharge)
function tds_log_likelihood(θ, y, x)
    μ = θ[1] .+ θ[2] * log.(x) # compute expected values
    ll = logpdf.(Normal.(μ, θ[3]), y) # compute log-likelihood for each observation
    return sum(ll) # return the sum log-likelihood
end
# Optim.optimize can use bounded optimization or unbounded
# It also minimizes the function so we want to minimize the negative log-likelihood
lower = [0.0, -1000.0, 1.0]
upper = [1000.0, 1000.0, 100.0]
θ_init = [500.0, 0.0, 50.0]
neg_ll(θ) = -tds_log_likelihood(θ, tds.tds_mgL, tds.discharge_cms)
optim_out = Optim.optimize(neg_ll, lower, upper, θ_init)
θ̂ = optim_out.minimizer
```
:::
::: {.column width=30%}
```{julia}
#| echo: false
#| output: true
θ̂ = Int.(round.(θ̂; digits=0))
@show θ̂;
```
:::
::::

::: {.notes}
Of course, this will only get you a point estimate: getting the sampling distribution or similar uncertainties for non-normal models is more involved and requires additional methods. More on this later this semester!
:::

## Whither Parameter Uncertainty?

So far we have neglected uncertainty in the parameter estimates. This is the last piece we will need to infer a fully generative model.

For frequentist statistics, this is reflected in the **sampling distribution**, which reflects how uncertainty in the data propagates to uncertainty in the parameter estimates.

For Bayesian statistics, this will pop out of the inference process naturally.

## The "Linear" Part of a Linear Model

The regression in a linear model can be a polynomial, or any other functional form, *e.g.*

$$
\begin{align*}
Y_i &= a + bX_i + cX_i^2 + \varepsilon_i \\
\varepsilon_i &\sim \text{Normal}(0, \sigma^2)
\end{align*}
$$

Now need to use numerical methods to maximize likelihood.

# Other Distributions and Generalized Linear Models

## Distributions Are Assumptions

**Specifying a distribution is making an assumption about observations and any applicable constraints.**

Examples: If your observations are...

- Continuous and fat-tailed? **Cauchy distribution**
- Continuous and bounded? **Beta distribution**
- Sums of positive random variables? **Gamma or Normal distribution**.

## "What Distribution Should I Use?"

**There is no right answer to this, no matter what a statistical test tells you.**

- What assumptions are justifiable from theory?
- What information do you have? 

## "What Distribution Should I Use?"

For example, suppose our data are counts of events:

- If you know something about **rates**, you can use a Poisson distribution
- If you know something about **probabilities**, you can use a Binomial distribution. 

## Generalized Linear Models

:::: {.columns}
::: {.column width=50%}

### Linear Models

Expected value: regression on predictors

$$
\begin{align*}
Y_i &\sim \text{Normal}(\mu_i, \sigma^2) \\
\mu_i &= \beta_0 + \beta_X X_i + \beta_Z Z_i
\end{align*}
$$
:::

::: {.column width=50%}
::: {.fragment .fade-in}
### GLMs

Expected value: **some function** of a regression

$$
\begin{align*}
Y_i &\sim \text{Bernoulli}(p_i) \\
f(p_i) &= \beta_0 + \beta_X X_i + \beta_Z Z_i
\end{align*}
$$
:::
:::
::::

## Links and Inverse Links

$$
\begin{align*}
Y_i &\sim \text{Bernoulli}(p_i) \\
{\color{purple}f(p_i)} &= \beta_0 + \beta_X X_i + \beta_Z Z_i
\end{align*}
$$

The function $f$ is called a **link function**.

$f^{-1}$ is the **inverse link**: 

$$p_i = f^{-1}(\beta_0 + \beta_X X_i + \beta_Z Z_i).$$

Links are effectively determined by your choice of distribution.

## Example: Logit link

For example, Bernoulli distributions often use the **logit** link to map probabilities to linear values.

:::: {.columns}
::: {.column width=50%}

$$\text{logit}(p_i) = \log \frac{p_i}{1-p_i}$$

$$\text{logit}^{-1}(q_i) = \frac{\exp(q_i)}{1 + \exp(q_i)}$$

:::
::: {.column width=50%}
```{julia}
f(p) = log(p / (1 - p))
prob = 0:0.01:1
plot(prob, 
    f.(prob), 
    linewidth=3,
    xlabel="Probability",
    ylabel="Logit Response"
)
plot!(size=(600, 400))
```
:::
::::

## Q-Q Plots

::: {.columns}
::: {.column width=50%}
One exploratory method to see if your data is reasonably described by a theoretical distribution is a **Q-Q plot**.
:::
::: {.column width=50%}
```{julia}
#| label: fig-norm-qq
#| code-fold: true
#| code-overflow: wrap
#| echo: true

samps = rand(Normal(0, 3), 20)
qqplot(Normal, samps, tickfontsize=16, guidefontsize=18, linewidth=3, markersize=6)
xlabel!("Theoretical Quantiles")
ylabel!("Empirical Quantiles")
plot!(size=(500, 450))
```
:::
::::

## Fat-Tailed Data and Q-Q Plots

```{julia}
#| label: fig-cauchy-qq
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| layout-ncol: 2
#| fig-cap: "Q-Q Plot for Cauchy Data and Normal Distribution"
#| fig-subcap: 
#|  - "Normal vs Cauchy Distribution"
#|  - "Q-Q Plot"

## generate fat-tailed residuals
cauchy_samps = rand(Cauchy(0, 1), 100)

# make plots
# scatterplot of observations
p1 = plot(Normal(0, 2), linewidth=3, color=:green, label="Normal Distribution", yaxis=false, legend=:outerbottom)
plot!(p1, Cauchy(0, 1), linewidth=3, color=:orange, linestyle=:dash, label="Cauchy Distribution")
xlims!(p1, (-10, 10))
xlabel!("Value")
plot!(p1, size=(600, 550))

# densities of residual distributions
p2 = qqplot(Normal, cauchy_samps, tickfontsize=16, guidefontsize=18, linewidth=3, markersize=6)
xlabel!(p2, "Theoretical Quantiles")
ylabel!(p2, "Empirical Quantiles")
plot!(p2, size=(500, 450))

display(p1)
display(p2)
```

# Describing Uncertainty


## Confidence Intervals

:::: {.columns}
::: {.column width=50%}
Frequentist estimates have **confidence intervals**, which will contain the "true" parameter value for $\alpha$% of data samples.

No guarantee that an individual CI contains the true value (with any "probability")!
:::

::: {.column width=50%}

![Horseshoe Illustration](https://www.wikihow.com/images/thumb/2/20/Throw-a-Horseshoe-Step-4-Version-4.jpg/aid448076-v4-728px-Throw-a-Horseshoe-Step-4-Version-4.jpg){width=90%}

::: {.caption}
Source: <https://www.wikihow.com/Throw-a-Horseshoe>
:::

:::
::::

::: {.notes}
Confidence intervals only capture uncertainty in **parameter inferences** due to data uncertainty, though this language sometimes gets misused to also refer to data/estimand uncertainty. 

:::

## Example: 95% CIs for N(0.4, 2)

```{julia}
#| label: fig-cis
#| code-fold: true
#| code-overflow: wrap
#| echo: true
#| layout-ncol: 2
#| fig-cap: "Display of 95% confidence intervals"
#| fig-subcap: 
#|  - "Sample Size 100"
#|  - "Sample Size 1,000"

# set up distribution
mean_true = 0.4
n_cis = 100 # number of CIs to compute
dist = Normal(mean_true, 2)

# use sample size of 100
samples = rand(dist, (100, n_cis))
# mapslices broadcasts over a matrix dimension, could also use a loop
sample_means = mapslices(mean, samples; dims=1)
sample_sd = mapslices(std, samples; dims=1) 
mc_sd = 1.96 * sample_sd / sqrt(100)
mc_ci = zeros(n_cis, 2) # preallocate
for i = 1:n_cis
    mc_ci[i, 1] = sample_means[i] - mc_sd[i]
    mc_ci[i, 2] = sample_means[i] + mc_sd[i]
end
# find which CIs contain the true value
ci_true = (mc_ci[:, 1] .< mean_true) .&& (mc_ci[:, 2] .> mean_true)
# compute percentage of CIs which contain the true value
ci_frac1 = 100 * sum(ci_true) ./ n_cis

# plot CIs
p1 = plot([mc_ci[1, :]], [1, 1], linewidth=3, color=:deepskyblue, label="95% Confidence Interval", title="Sample Size 100", yticks=:false, legend=:false)
for i = 2:n_cis
    if ci_true[i]
        plot!(p1, [mc_ci[i, :]], [i, i], linewidth=2, color=:deepskyblue, label=:false)
    else
        plot!(p1, [mc_ci[i, :]], [i, i], linewidth=2, color=:red, label=:false)
    end
end
vline!(p1, [mean_true], color=:black, linewidth=2, linestyle=:dash, label="True Value") # plot true value as a vertical line
xaxis!(p1, "Estimate")
plot!(p1, size=(500, 350)) # resize to fit slide

# use sample size of 1000
samples = rand(dist, (1000, n_cis))
# mapslices broadcasts over a matrix dimension, could also use a loop
sample_means = mapslices(mean, samples; dims=1)
sample_sd = mapslices(std, samples; dims=1) 
mc_sd = 1.96 * sample_sd / sqrt(1000)
mc_ci = zeros(n_cis, 2) # preallocate
for i = 1:n_cis
    mc_ci[i, 1] = sample_means[i] - mc_sd[i]
    mc_ci[i, 2] = sample_means[i] + mc_sd[i]
end
# find which CIs contain the true value
ci_true = (mc_ci[:, 1] .< mean_true) .&& (mc_ci[:, 2] .> mean_true)
# compute percentage of CIs which contain the true value
ci_frac2 = 100 * sum(ci_true) ./ n_cis

# plot CIs
p2 = plot([mc_ci[1, :]], [1, 1], linewidth=3, color=:deepskyblue, label="95% Confidence Interval", title="Sample Size 1,000", yticks=:false, legend=:false)
for i = 2:n_cis
    if ci_true[i]
        plot!(p2, [mc_ci[i, :]], [i, i], linewidth=2, color=:deepskyblue, label=:false)
    else
        plot!(p2, [mc_ci[i, :]], [i, i], linewidth=2, color=:red, label=:false)
    end
end
vline!(p2, [mean_true], color=:black, linewidth=2, linestyle=:dash, label="True Value") # plot true value as a vertical line
xaxis!(p2, "Estimate")
plot!(p2, size=(500, 350)) # resize to fit slide

display(p1)
display(p2)
```

`{julia} Int64(round(ci_frac1))`% of the CIs contain the true value (left) vs. `{julia} Int64(round(ci_frac2))`% (right)

## Projection Intervals

:::: {.columns}
::: {.column width=50%}
**Projection intervals** capture uncertainty in an estimand.

**With what probability would I see a particular outcome in the future?**

Often need to construct these using **simulation**.
:::
::: {.column width=50%}
```{julia}
#| label: fig-credible-interval
#| fig-cap: Two different 95% credible intervals.

plot(Gamma(7.5), linewidth=3, xlabel="Data/Parameter", label=:false, legend=:outerbottom)
q1 = quantile(Gamma(7.5), [0.05, 0.95])
q2 = quantile(Gamma(7.5), [0.01, 0.91])
q3 = quantile(Gamma(7.5), [0.09, 0.99])
gamma_pdf(x) = pdf(Gamma(7.5), x)
plot!(q1[1]:0.01:q1[2], gamma_pdf(q1[1]:0.01:q1[2]), fillrange=zero(q1[1]:0.01:q1[2]), alpha=0.2, label="90% Interval 1")
plot!(q2[1]:0.01:q2[2], gamma_pdf(q2[1]:0.01:q2[2]), fillrange=zero(q2[1]:0.01:q2[2]), alpha=0.2, label="90% Interval 2")
plot!(q3[1]:0.01:q3[2], gamma_pdf(q3[1]:0.01:q3[2]), fillrange=zero(q3[1]:0.01:q3[2]), alpha=0.2, label="90% Interval 3")
plot!(size=(600, 650))
```
:::
::::

::: {.notes}
Due to this non-uniqueness, the typical convention is to use the "equal tailed" interval based on quantiles.
:::


# Upcoming Schedule

## Next Classes

**Wednesday**: Bayesian Statistics

**Next Week**: Temporal and Spatial Models and Errors

## Assessments

**Homework 1** due Friday (2/7).

# References

## References (Scroll for Full List)
