---
title: "Bayesian Statistics and Probability Models"
subtitle: "Lecture 04"
author: "Vivek Srikrishnan"
course: "BEE 4850"
institution: "Cornell University"
date: "January 31, 2024"
format:
    revealjs:
        slide-number: c/t
        show-slide-number: all
        center-title-slide: true
        width: 1280
        height: 720
        transition: none
        toc: true
        toc-depth: 1
        toc-title: "Overview"
        history: false
        link-external-newwindow: true
        theme: ../sass/slides.scss
        template-partials:
            - title-slide.html
        menu:
            numbers: true
        html-math-method: 
            method: mathjax
            url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
        include-in-header: mathjax-config.html
        date-format: long
        email-obfuscation: javascript
execute:
    freeze: auto
---

```{julia}
#| output: false

import Pkg
Pkg.activate(@__DIR__)
Pkg.instantiate()
```

```{julia}
#| output: false

using Random
using Distributions
using Plots
using StatsPlots
using StatsBase
using LaTeXStrings
using Measures
using CSV
using DataFrames
using Turing
using Optim

Random.seed!(1)
```

# Last Class(es)

## Probability Models

**Goal**: Write down a probability model for the data-generating process for $\mathbf{y}$.

This could be:

- Direct statistical model, $$\mathbf{y} \sim \mathcal{D}(\theta).$$
- Model for the residuals of a numerical model, $$\mathbf{r} = \mathbf{y} - F(\mathbf{x}) \sim \mathcal{D}(\theta).$$

## Model Fitting as Maximum Likelihood Estimation

We can interpret fitting a model (reducing error according to some loss or error metric) as maximizing the probability of observing our data from this data generating process.

# Accounting for Model Residuals

## The Energy Balance Model Revisited

Last class, we introduced the Energy Balance Model (EBM):

$$T_{i+1} = T_i + \frac{F_i - \lambda T_i}{cd} \Delta t$$

Let's write this as $\mathbf{T} = \Lambda(\mathbf{F})$.

```{julia}
#| output: false
#| echo: false

# use default values of S=3.2°C, d=100m, α=1.3
function ebm(rf_nonaerosol, rf_aerosol; p=(3.2, 100, 1.3))
    # set up model parameters
    S, d, α = p # this unpacks the parameter tuple into variables
    F2xCO₂ = 4.0 # radiative forcing [W/m²] for a doubling of CO₂
    λ = F2xCO₂ / S

    c = 4.184e6 # heat capacity/area [J/K/m²]
    C = c*d # heat capacity of mixed layer (per area)
    F = rf_nonaerosol + α*rf_aerosol # radiative forcing
    Δt = 31558152. # annual timestep [s]

    T = zero(F)
    for i in 1:length(F)-1
        T[i+1] = T[i] + (F[i] - λ*T[i])/C * Δt
    end
    
    # return after normalizing to reference period
    return T .- mean(T[1:20])
end

# Dataset from https://zenodo.org/record/3973015
# The CSV is read into a DataFrame object, and we specify that it is comma delimited
forcings_all_85 = CSV.read("data/climate/ERF_ssp585_1750-2500.csv", DataFrame, delim=",")

# Separate out the individual components
forcing_co2_85 = forcings_all_85[!,"co2"]
# Get total aerosol forcings
forcing_aerosol_rad_85 = forcings_all_85[!,"aerosol-radiation_interactions"]
forcing_aerosol_cloud_85 = forcings_all_85[!,"aerosol-cloud_interactions"]
forcing_aerosol_85 = forcing_aerosol_rad_85 + forcing_aerosol_cloud_85
forcing_total_85 = forcings_all_85[!,"total"]
forcing_non_aerosol_85 = forcing_total_85 - forcing_aerosol_85
forcing_other_85 = forcing_total_85 - (forcing_co2_85 + forcing_aerosol_85)

forcings_all_26 = CSV.read("data/climate/ERF_ssp126_1750-2500.csv", DataFrame, delim=",")

# Separate out the individual components
forcing_co2_26 = forcings_all_26[!,"co2"]
# Get total aerosol forcings
forcing_aerosol_rad_26 = forcings_all_26[!,"aerosol-radiation_interactions"]
forcing_aerosol_cloud_26 = forcings_all_26[!,"aerosol-cloud_interactions"]
forcing_aerosol_26 = forcing_aerosol_rad_26 + forcing_aerosol_cloud_26
forcing_total_26 = forcings_all_26[!,"total"]
forcing_non_aerosol_26 = forcing_total_26 - forcing_aerosol_26
forcing_other_26 = forcing_total_26 - (forcing_co2_26 + forcing_aerosol_26)

t = time_forcing = Int64.(forcings_all_85[!,"year"]) # Ensure that years are interpreted as integers
sim_years = 1850:2100 # model years for projections
sim_idx = indexin(sim_years, t)

temps = CSV.read("data/climate/HadCRUT.5.0.1.0.analysis.summary_series.global.annual.csv", DataFrame, delim=",")

time_obs = temps[:, 1]
temp_obs = temps[:, 2]
temp_lo = temps[:, 3]
temp_hi = temps[:, 4]

# generate simulations
hind_years = 1850:2020 # model years to simulate for fitting
sim_years = 1850:2100 # model years for projections
idx = indexin(hind_years, t) # find indices in t vector of simulation years
# since we specified default values for p, those are used for the parameters
temp_default = ebm(forcing_non_aerosol_85[idx], forcing_aerosol_85[idx]) 

temp_obs = temp_obs[indexin(hind_years, time_obs)] # filter to simulated years for plotting
temp_lo = temp_lo[indexin(hind_years, time_obs)] # filter to simulated years for plotting
temp_hi = temp_hi[indexin(hind_years, time_obs)] # filter to simulated years for plotting
temp_obs = temp_obs .- mean(temp_obs[1:20]) # re-normalize to be consistent with the model
temp_lo = temp_lo .- mean(temp_obs[1:20]) # re-normalize to be consistent with the model
temp_hi = temp_hi .- mean(temp_obs[1:20]) # re-normalize to be consistent with the model
```

